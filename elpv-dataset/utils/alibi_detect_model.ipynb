{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/simplifing-image-outlier-detection-with-alibi-detect-6aea686bf7ba\n",
    "# source venv/bin/activate\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Flatten, Dense, Reshape, Input\n",
    "from alibi_detect.od import OutlierAE\n",
    "from alibi_detect.utils.visualize import plot_feature_outlier_image\n",
    "from train_test_split import load_and_split_images\n",
    "\n",
    "# Set parent directory and image folder paths\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir))\n",
    "image_folder = os.path.join(parent_dir, 'non_defective_images')\n",
    "\n",
    "# Load and split images\n",
    "train, test = load_and_split_images(image_folder, train_ratio=0.8)\n",
    "train = train.astype('float32') / 255.0\n",
    "test = test.astype('float32') / 255.0\n",
    "\n",
    "# Model parameters\n",
    "encoding_dim = 1024\n",
    "dense_dim = [8, 8, 128]\n",
    "\n",
    "# Define the encoder\n",
    "encoder_net = tf.keras.Sequential([\n",
    "    Input(shape=train[0].shape),\n",
    "    Conv2D(64, 4, strides=2, padding='same', activation='relu'),\n",
    "    Conv2D(128, 4, strides=2, padding='same', activation='relu'),\n",
    "    Conv2D(512, 4, strides=2, padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(encoding_dim)\n",
    "])\n",
    "\n",
    "# Define the decoder\n",
    "decoder_net = tf.keras.Sequential([\n",
    "    Input(shape=(encoding_dim,)),\n",
    "    Dense(np.prod(dense_dim)),\n",
    "    Reshape(target_shape=dense_dim),\n",
    "    Conv2DTranspose(256, 4, strides=2, padding='same', activation='relu'),\n",
    "    Conv2DTranspose(64, 4, strides=2, padding='same', activation='relu'),\n",
    "    Conv2DTranspose(3, 4, strides=2, padding='same', activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Create the OutlierAE model\n",
    "od = OutlierAE(\n",
    "    threshold=0.001,\n",
    "    encoder_net=encoder_net,\n",
    "    decoder_net=decoder_net\n",
    ")\n",
    "\n",
    "# Compile and train the model\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=1e-4)  # Corrected keyword\n",
    "od.fit(train, epochs=100, verbose=True, optimizer=adam)\n",
    "\n",
    "# Infer threshold on test set\n",
    "od.infer_threshold(test, threshold_perc=95)\n",
    "\n",
    "# Test the model on the test set\n",
    "preds = od.predict(test, outlier_type='instance',\n",
    "                   return_instance_score=True,\n",
    "                   return_feature_score=True)\n",
    "\n",
    "# Get reconstructions\n",
    "recon = od.ae(test).numpy()\n",
    "\n",
    "# Visualize outliers\n",
    "plot_feature_outlier_image(preds, test, \n",
    "                           X_recon=recon,  \n",
    "                           max_instances=5,\n",
    "                           outliers_only=True,\n",
    "                           figsize=(15, 15))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "for i, fpath in enumerate(glob.glob(path_test)):\n",
    "    if(preds['data']['is_outlier'][i] == 1):\n",
    "        source = fpath\n",
    "        shutil.copy(source, 'img\\\\') \n",
    "        \n",
    "filenames = [os.path.basename(x) for x in glob.glob(path_test, recursive=True)]\n",
    "\n",
    "dict1 = {'Filename': filenames,\n",
    "     'instance_score': preds['data']['instance_score'],\n",
    "     'is_outlier': preds['data']['is_outlier']}\n",
    "     \n",
    "df = pd.DataFrame(dict1)\n",
    "df_outliers = df[df['is_outlier'] == 1]\n",
    "\n",
    "print(df_outliers)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
