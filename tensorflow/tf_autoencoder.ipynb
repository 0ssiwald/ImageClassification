{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/generative/autoencoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "from log_training import TrainingLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image data \n",
    "def img_to_np(path, resize = True, extract_labels=False):  \n",
    "    img_array = []\n",
    "    labels = []\n",
    "    fpaths = glob.glob(path, recursive=True)\n",
    "    for fname in fpaths:\n",
    "        if(extract_labels): \n",
    "            if '_bad' in os.path.basename(fname):\n",
    "                labels.append(1)  # 1 for outlier\n",
    "            else:\n",
    "                labels.append(0)  # 0 for non-outlier\n",
    "        img = Image.open(fname).convert(\"L\") # Grayscale when using \"RGB\" you have to change the encoder and decoder \n",
    "        if(resize): img = img.resize((64,64))\n",
    "        img_array.append(np.asarray(img))\n",
    "    images = np.array(img_array)\n",
    "    if(extract_labels): return images, np.array(labels)\n",
    "    return images\n",
    "\n",
    "path_train = r'C:\\Users\\Ossi\\Desktop\\ImageClassification\\elpv-dataset\\train_without_bad_images\\**\\*'\n",
    "path_test = r'C:\\Users\\Ossi\\Desktop\\ImageClassification\\elpv-dataset\\test_images\\**\\*'\n",
    "path_treshold = r'C:\\Users\\Ossi\\Desktop\\ImageClassification\\elpv-dataset\\train_without_good_images\\**\\*'\n",
    "\n",
    "train = img_to_np(path_train)\n",
    "test, test_labels = img_to_np(path_test, extract_labels=True)\n",
    "set_bad_threshold = img_to_np(path_treshold)\n",
    "train = train.astype('float32') / 255.0\n",
    "test = test.astype('float32') / 255.0\n",
    "set_bad_threshold  = set_bad_threshold.astype('float32') / 255.0\n",
    "# Reshape to include the channel dimension -> needed with grayscale conversion\n",
    "train = np.expand_dims(train, axis=-1)\n",
    "test = np.expand_dims(test, axis=-1)\n",
    "set_bad_threshold = np.expand_dims(set_bad_threshold, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10\n",
    "LEARNING_RATE=1e-4\n",
    "BATCH_SIZE=32\n",
    "OPTIMIZER='adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Autoencoder model\n",
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    # For logging\n",
    "    def summary(self):\n",
    "        return self.encoder.summary(), self.decoder.summary()\n",
    "\n",
    "# Model parameters\n",
    "encoding_dim = 1024\n",
    "dense_dim = [8, 8, 128]\n",
    "\n",
    "# Define the encoder\n",
    "encoder = tf.keras.Sequential([\n",
    "    layers.Input(shape=(64, 64, 1)),  # 64x64 pixels with one color channel (gray)\n",
    "     # extracts 64 feature maps using 4x4 filters | output dimensions are reduced by half due to the stride of 2.\n",
    "    layers.Conv2D(64, 4, strides=2, padding='same', activation='relu'),# (64, 64, 1) -> (32, 32, 64)\n",
    "    layers.Conv2D(128, 4, strides=2, padding='same', activation='relu'), # extracts 64 feature maps using 4x4 filters (32, 32, 64) -> (16, 16, 128)\n",
    "    layers.Conv2D(512, 4, strides=2, padding='same', activation='relu'), # (16, 16, 128) -> (8, 8, 512)\n",
    "    layers.Flatten(), # flattens the 3D tensor (8, 8, 512) into a 1D vector of size 32768\n",
    "    layers.Dense(encoding_dim) # fully connected layer reduces the flattened vector to a 1D vector of size 1024\n",
    "])\n",
    "\n",
    "# Define the decoder\n",
    "decoder = tf.keras.Sequential([\n",
    "    layers.Input(shape=(encoding_dim,)),\n",
    "    layers.Dense(np.prod(dense_dim)), # takes 1024-dimensional vector and maps it to size 8192, which corresponds to the flattened form of the next target shape (8, 8, 128)\n",
    "    layers.Reshape(target_shape=dense_dim), # reshapes 8192 into (8, 8, 128)\n",
    "    layers.Conv2DTranspose(256, 4, strides=2, padding='same', activation='relu'), # deconvolution -> increases the depth to 256 feature maps (8, 8, 128) -> (16, 16, 256)\n",
    "    layers.Conv2DTranspose(64, 4, strides=2, padding='same', activation='relu'), # (16, 16, 256) -> (32, 32, 64)\n",
    "    layers.Conv2DTranspose(1, 4, strides=2, padding='same', activation='sigmoid')  # (32, 32, 64) -> (64, 64, 1)\n",
    "])\n",
    "\n",
    "# Create the Autoencoder model\n",
    "autoencoder = Autoencoder(encoder, decoder)\n",
    "# loss function is Mean Squared Error(MSE)\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='mse')\n",
    "\n",
    "# Train the model\n",
    "# not shure if validation_split is best but validation_data I dont understand completely \n",
    "history = autoencoder.fit(train, train, epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the reconstruction error for the test set\n",
    "reconstructions = autoencoder.predict(test)\n",
    "reconstruction_errors = np.mean(np.square(test - reconstructions), axis=(1, 2, 3))\n",
    "\n",
    "# Set a threshold for classifying outliers \n",
    "# 90 means 90% are classified as inliners | because test set is 50% outliers 50 makes sense I think\n",
    "# maybe make testset with only outliers and set a threshold of 95 for example \n",
    "threshold = np.percentile(reconstruction_errors, 50)  \n",
    "\n",
    "# Predict whether each test instance is an outlier\n",
    "predicted_labels = (reconstruction_errors > threshold).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log all the data and store it\n",
    "logger = TrainingLogger(epochs=EPOCHS, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE, optimizer=OPTIMIZER)\n",
    "logger.capture_model_summary(autoencoder)\n",
    "logger.update_train_metrics(val_accuracy=None, val_loss=history.history['val_loss'], accuracy=None, loss=history.history['loss'])\n",
    "logger.update_test_metrics(accuracy=accuracy, loss=None)\n",
    "logger.print_and_save_log()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
