{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/simplifing-image-outlier-detection-with-alibi-detect-6aea686bf7ba\n",
    "\n",
    "# GPU https://www.youtube.com/watch?v=NrJz3ACosJA&t=6s conda activate py310\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D,\\\n",
    "    Dense, Layer, Reshape, InputLayer, Flatten, Input, MaxPooling2D\n",
    "from alibi_detect.od import OutlierAE\n",
    "from alibi_detect.utils.visualize import plot_instance_score, plot_feature_outlier_image\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image data \n",
    "def img_to_np(path, resize = True, extract_labels=False):  \n",
    "    img_array = []\n",
    "    labels = []\n",
    "    fpaths = glob.glob(path, recursive=True)\n",
    "    for fname in fpaths:\n",
    "        if(extract_labels): \n",
    "            if '_bad' in os.path.basename(fname):\n",
    "                labels.append(1)  # 1 for outlier\n",
    "            else:\n",
    "                labels.append(0)  # 0 for non-outlier\n",
    "        img = Image.open(fname).convert(\"L\") # Grayscale when using \"RGB\" you have to change the encoder and decoder \n",
    "        if(resize): img = img.resize((64,64))\n",
    "        img_array.append(np.asarray(img))\n",
    "    images = np.array(img_array)\n",
    "    if(extract_labels): return images, np.array(labels)\n",
    "    return images\n",
    "\n",
    "path_train = r'C:\\Users\\Ossi\\Desktop\\ImageClassification\\elpv-dataset\\train_without_bad_images\\**\\*'\n",
    "path_test = r'C:\\Users\\Ossi\\Desktop\\ImageClassification\\elpv-dataset\\test_images\\**\\*'\n",
    "path_treshold = r'C:\\Users\\Ossi\\Desktop\\ImageClassification\\elpv-dataset\\train_without_good_images\\**\\*'\n",
    "\n",
    "train = img_to_np(path_train)\n",
    "test, test_labels = img_to_np(path_test, extract_labels=True)\n",
    "set_bad_threshold = img_to_np(path_treshold)\n",
    "train = train.astype('float32') / 255.0\n",
    "test = test.astype('float32') / 255.0\n",
    "set_bad_threshold  = set_bad_threshold.astype('float32') / 255.0\n",
    "# Reshape to include the channel dimension -> needed with grayscale conversion\n",
    "train = np.expand_dims(train, axis=-1)\n",
    "test = np.expand_dims(test, axis=-1)\n",
    "set_bad_threshold = np.expand_dims(set_bad_threshold, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [=] - 0s 27ms/step - loss_ma: 0.0380\n",
      "15/15 [=] - 0s 29ms/step - loss_ma: 0.0244\n",
      "15/15 [=] - 0s 30ms/step - loss_ma: 0.0136\n",
      "15/15 [=] - 0s 29ms/step - loss_ma: 0.0111\n",
      "15/15 [=] - 0s 29ms/step - loss_ma: 0.0107\n",
      "15/15 [=] - 0s 29ms/step - loss_ma: 0.0100\n",
      "15/15 [=] - 0s 29ms/step - loss_ma: 0.0099\n",
      "15/15 [=] - 0s 29ms/step - loss_ma: 0.0098\n",
      "15/15 [=] - 0s 30ms/step - loss_ma: 0.0100\n",
      "15/15 [=] - 0s 29ms/step - loss_ma: 0.0100\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "encoding_dim = 1024\n",
    "dense_dim = [8, 8, 128]\n",
    "\n",
    "# Define the encoder\n",
    "encoder_net = tf.keras.Sequential([\n",
    "    Input(shape=(64, 64, 1)),  # Updated input shape for grayscale images\n",
    "    Conv2D(64, 4, strides=2, padding='same', activation='relu'),\n",
    "    Conv2D(128, 4, strides=2, padding='same', activation='relu'),\n",
    "    Conv2D(512, 4, strides=2, padding='same', activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(encoding_dim)\n",
    "])\n",
    "\n",
    "# Define the decoder\n",
    "decoder_net = tf.keras.Sequential([\n",
    "    Input(shape=(encoding_dim,)),\n",
    "    Dense(np.prod(dense_dim)),\n",
    "    Reshape(target_shape=dense_dim),\n",
    "    Conv2DTranspose(256, 4, strides=2, padding='same', activation='relu'),\n",
    "    Conv2DTranspose(64, 4, strides=2, padding='same', activation='relu'),\n",
    "    Conv2DTranspose(1, 4, strides=2, padding='same', activation='sigmoid')  # Updated output channels to 1\n",
    "])\n",
    "\n",
    "# Create the OutlierAE model\n",
    "od = OutlierAE(\n",
    "    threshold=0.001,\n",
    "    encoder_net=encoder_net,\n",
    "    decoder_net=decoder_net\n",
    ")\n",
    "\n",
    "# Compile and train the model\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "od.fit(train, epochs=10, verbose=True, optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.98%\n"
     ]
    }
   ],
   "source": [
    "# Infer threshold on test set\n",
    "od.infer_threshold(set_bad_threshold, threshold_perc=95)\n",
    "\n",
    "# Test the model on the test set\n",
    "preds = od.predict(test, outlier_type='instance',\n",
    "                   return_instance_score=True,\n",
    "                   return_feature_score=True)\n",
    "\n",
    "predicted_labels = preds['data']['is_outlier']\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
