{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/drive/1ZZXnCjFEOkp_KdNcNabd14yok0BAIuwS#forceEdit=true&sandboxMode=true&scrollTo=wdPxFvHdTLRK\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from log_training import TrainingLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LOAD AND SPLIT DATASET\n",
    "path_train = r'C:\\Users\\oswal\\Desktop\\ImageClassification\\elpv-dataset\\train_with_bad_images\\**\\*'\n",
    "path_test = r'C:\\Users\\oswal\\Desktop\\ImageClassification\\elpv-dataset\\test_images\\**\\*'\n",
    "\n",
    "# Prepare image data \n",
    "def img_to_np(path, resize = True, extract_labels=False):  \n",
    "    img_array = []\n",
    "    labels = []\n",
    "    fpaths = glob.glob(path, recursive=True)\n",
    "    for fname in fpaths:\n",
    "        if(extract_labels): \n",
    "            if '_bad' in os.path.basename(fname):\n",
    "                labels.append(1)  # 1 for outlier\n",
    "            else:\n",
    "                labels.append(0)  # 0 for non-outlier\n",
    "        img = Image.open(fname).convert(\"L\") # Grayscale when using \"RGB\" you have to change the encoder and decoder \n",
    "        if(resize): img = img.resize((64,64))\n",
    "        img_array.append(np.asarray(img))\n",
    "    images = np.array(img_array)\n",
    "    if(extract_labels): return images, np.array(labels)\n",
    "    return images\n",
    "\n",
    "test_images, test_labels = img_to_np(path_test, extract_labels=True)\n",
    "train_images, train_labels = img_to_np(path_train, extract_labels=True)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "class_names = ['good', 'bad']\n",
    "\n",
    "# Let's look at a one image\n",
    "IMG_INDEX = 7  # change this to look at other images\n",
    "#plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
    "#plt.xlabel(class_names[train_labels[IMG_INDEX]])\n",
    "#plt.show() # uncomment for prview of image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10\n",
    "OPTIMIZER=\"adam\" #change manually !!!\n",
    "BATCH_SIZE=32\n",
    "LEARNING_RATE=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the Convolutional Base\n",
    "model = models.Sequential()\n",
    "#  32, 32, 3 means we will process 32 filters of size 3x3 | imput shape 64, 64, 1 means 64x64 pixels with one chanell for RGB change to 3\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
    "# pooling layses to downsample our feature maps and reduce their dimensions\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add dense layers to classify into two classes true false \n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Last layer with two neurons to classify between true and false \n",
    "model.add(layers.Dense(2))\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# Train model with validation split\n",
    "history = model.fit(train_images, train_labels, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "#history = model.fit(train_images, train_labels, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "#                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "# Log all the data and store it\n",
    "logger = TrainingLogger(epochs=EPOCHS, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE, optimizer=OPTIMIZER)\n",
    "logger.capture_model_summary(model)\n",
    "logger.update_train_metrics(val_accuracy=history.history['val_accuracy'], val_loss=history.history['val_loss'], accuracy=history.history['accuracy'], loss=history.history['val_loss'])\n",
    "logger.update_test_metrics(accuracy=test_acc, loss=test_loss)\n",
    "logger.print_and_save_log()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
