{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/drive/1ZZXnCjFEOkp_KdNcNabd14yok0BAIuwS#forceEdit=true&sandboxMode=true&scrollTo=wdPxFvHdTLRK\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import datasets, layers, models, optimizers \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from log_training import TrainingLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\oswal\\\\Desktop\\\\ImageClassification\\\\elpv-dataset\\\\test_images\\\\bad'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(extract_labels): \u001b[38;5;28;01mreturn\u001b[39;00m images, np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m images\n\u001b[1;32m---> 23\u001b[0m test_images, test_labels \u001b[38;5;241m=\u001b[39m \u001b[43mimg_to_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m train_images, train_labels \u001b[38;5;241m=\u001b[39m img_to_np(path_train, extract_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Normalize pixel values to be between 0 and 1\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mimg_to_np\u001b[1;34m(path, resize, extract_labels)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m         labels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# 0 for non-outlier\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Grayscale when using \"RGB\" you have to change the encoder and decoder \u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(resize): img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m))\n\u001b[0;32m     18\u001b[0m img_array\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39masarray(img))\n",
      "File \u001b[1;32mc:\\Users\\oswal\\anaconda3\\envs\\py310\\lib\\site-packages\\PIL\\Image.py:3431\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3431\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3432\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\oswal\\\\Desktop\\\\ImageClassification\\\\elpv-dataset\\\\test_images\\\\bad'"
     ]
    }
   ],
   "source": [
    "#  LOAD AND SPLIT DATASET\n",
    "path_train = r'C:\\Users\\oswal\\Desktop\\ImageClassification\\elpv-dataset\\train_with_bad_images\\**\\*'\n",
    "path_test = r'C:\\Users\\oswal\\Desktop\\ImageClassification\\elpv-dataset\\test_images\\**\\*'\n",
    "\n",
    "# Prepare image data \n",
    "def img_to_np(path, resize = True, extract_labels=False):  \n",
    "    img_array = []\n",
    "    labels = []\n",
    "    fpaths = glob.glob(path, recursive=True)\n",
    "    for fname in fpaths:\n",
    "        if(extract_labels): \n",
    "            if '_bad' in os.path.basename(fname):\n",
    "                labels.append(1)  # 1 for outlier\n",
    "            else:\n",
    "                labels.append(0)  # 0 for non-outlier\n",
    "        img = Image.open(fname).convert(\"L\") # Grayscale when using \"RGB\" you have to change the encoder and decoder \n",
    "        if(resize): img = img.resize((64,64))\n",
    "        img_array.append(np.asarray(img))\n",
    "    images = np.array(img_array)\n",
    "    if(extract_labels): return images, np.array(labels)\n",
    "    return images\n",
    "\n",
    "test_images, test_labels = img_to_np(path_test, extract_labels=True)\n",
    "train_images, train_labels = img_to_np(path_train, extract_labels=True)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "class_names = ['good', 'bad']\n",
    "\n",
    "# Let's look at a one image\n",
    "IMG_INDEX = 7  # change this to look at other images\n",
    "#plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
    "#plt.xlabel(class_names[train_labels[IMG_INDEX]])\n",
    "#plt.show() # uncomment for prview of image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10\n",
    "OPTIMIZER=\"adam\" #change manually !!!\n",
    "BATCH_SIZE=32\n",
    "LEARNING_RATE=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the Convolutional Base\n",
    "model = models.Sequential()\n",
    "#  32, 32, 3 means we will process 32 filters of size 3x3 | imput shape 64, 64, 1 means 64x64 pixels with one chanell for RGB change to 3\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
    "# pooling layses to downsample our feature maps and reduce their dimensions\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None)) # standard pooling layer\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None))\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "# Add dense layers to classify into two classes true false \n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Last layer with two neurons to classify between true and false \n",
    "model.add(layers.Dense(2))\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mLEARNING_RATE),\n\u001b[0;32m      2\u001b[0m               loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m      3\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train model with validation split\u001b[39;00m\n\u001b[0;32m      5\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_images, train_labels, epochs\u001b[38;5;241m=\u001b[39mEPOCHS, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m      6\u001b[0m                     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# Train model with validation split\n",
    "history = model.fit(train_images, train_labels, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "#history = model.fit(train_images, train_labels, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "#                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "# Log all the data and store it\n",
    "logger = TrainingLogger(epochs=EPOCHS, learning_rate=LEARNING_RATE, batch_size=BATCH_SIZE, optimizer=OPTIMIZER)\n",
    "logger.capture_model_summary(model)\n",
    "logger.update_train_metrics(val_accuracy=history.history['val_accuracy'], val_loss=history.history['val_loss'], accuracy=history.history['accuracy'], loss=history.history['val_loss'])\n",
    "logger.update_test_metrics(accuracy=test_acc, loss=test_loss)\n",
    "logger.print_and_save_log()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
