{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'cell_images2/uninfected_train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m     32\u001b[0m datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcell_images2/uninfected_train/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcell_images2/uninfected_test/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     43\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(SIZE, SIZE),\n\u001b[0;32m     44\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     45\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     46\u001b[0m     )\n\u001b[0;32m     48\u001b[0m anomaly_generator \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcell_images2/parasitized/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     50\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(SIZE, SIZE),\n\u001b[0;32m     51\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     52\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     53\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\oswal\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py:1650\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1566\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1580\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1581\u001b[0m ):\n\u001b[0;32m   1582\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1583\u001b[0m \n\u001b[0;32m   1584\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1648\u001b[0m \u001b[38;5;124;03m            and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1652\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\oswal\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\preprocessing\\image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    562\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    565\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'cell_images2/uninfected_train/'"
     ]
    }
   ],
   "source": [
    "# https://youtu.be/q_tpFGHiRgg\n",
    "# Data from: https://lhncbc.nlm.nih.gov/LHC-publications/pubs/MalariaDatasets.html\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Size of our input images\n",
    "SIZE = 128\n",
    "\n",
    "#############################################################################\n",
    "#Define generators for training, validation and also anomaly data.\n",
    "\n",
    "batch_size = 64\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'cell_images2/uninfected_train/',\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'\n",
    "    )\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    'cell_images2/uninfected_test/',\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'\n",
    "    )\n",
    "\n",
    "anomaly_generator = datagen.flow_from_directory(\n",
    "    'cell_images2/parasitized/',\n",
    "    target_size=(SIZE, SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the autoencoder. \n",
    "#Try to make the bottleneck layer size as small as possible to make it easy for\n",
    "#density calculations and also picking appropriate thresholds. \n",
    "\n",
    "#Encoder\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(SIZE, SIZE, 3)))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "#Decoder\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(3, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model. \n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=500 // batch_size,\n",
    "        epochs=1000,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=75 // batch_size,\n",
    "        shuffle = True)\n",
    "\n",
    "\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all batches generated by the datagen and pick a batch for prediction\n",
    "#Just to test the model. \n",
    "data_batch = []  #Capture all training batches as a numpy array\n",
    "img_num = 0\n",
    "while img_num <= train_generator.batch_index:   #gets each generated batch of size batch_size\n",
    "    data = train_generator.next()\n",
    "    data_batch.append(data[0])\n",
    "    img_num = img_num + 1\n",
    "\n",
    "predicted = model.predict(data_batch[0])  #Predict on the first batch of images\n",
    "\n",
    "#Sanity check, view few images and corresponding reconstructions\n",
    "image_number = random.randint(0, predicted.shape[0])\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(data_batch[0][image_number])\n",
    "plt.subplot(122)\n",
    "plt.imshow(predicted[image_number])\n",
    "plt.show()\n",
    "\n",
    "#Let us examine the reconstruction error between our validation data (good/normal images)\n",
    "# and the anomaly images\n",
    "validation_error = model.evaluate_generator(validation_generator)\n",
    "anomaly_error = model.evaluate_generator(anomaly_generator)\n",
    "\n",
    "print(\"Recon. error for the validation (normal) data is: \", validation_error)\n",
    "print(\"Recon. error for the anomaly data is: \", anomaly_error)\n",
    "\n",
    "\n",
    "#Let us extract (or build) the encoder network, with trained weights.\n",
    "#This is used to get the compressed output (latent space) of the input image. \n",
    "#The compressed output is then used to calculate the KDE\n",
    "\n",
    "encoder_model = Sequential()\n",
    "encoder_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(SIZE, SIZE, 3), weights=model.layers[0].get_weights()) )\n",
    "encoder_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "encoder_model.add(Conv2D(32, (3, 3), activation='relu', padding='same', weights=model.layers[2].get_weights()))\n",
    "encoder_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "encoder_model.add(Conv2D(16, (3, 3), activation='relu', padding='same', weights=model.layers[4].get_weights()))\n",
    "encoder_model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "encoder_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate KDE using sklearn\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "#Get encoded output of input images = Latent space\n",
    "encoded_images = encoder_model.predict_generator(train_generator)\n",
    "\n",
    "# Flatten the encoder output because KDE from sklearn takes 1D vectors as input\n",
    "encoder_output_shape = encoder_model.output_shape #Here, we have 16x16x16\n",
    "out_vector_shape = encoder_output_shape[1]*encoder_output_shape[2]*encoder_output_shape[3]\n",
    "\n",
    "encoded_images_vector = [np.reshape(img, (out_vector_shape)) for img in encoded_images]\n",
    "\n",
    "#Fit KDE to the image latent data\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(encoded_images_vector)\n",
    "\n",
    "#Calculate density and reconstruction error to find their means values for\n",
    "#good and anomaly images. \n",
    "#We use these mean and sigma to set thresholds. \n",
    "def calc_density_and_recon_error(batch_images):\n",
    "    \n",
    "    density_list=[]\n",
    "    recon_error_list=[]\n",
    "    for im in range(0, batch_images.shape[0]-1):\n",
    "        \n",
    "        img  = batch_images[im]\n",
    "        img = img[np.newaxis, :,:,:]\n",
    "        encoded_img = encoder_model.predict([[img]]) # Create a compressed version of the image using the encoder\n",
    "        encoded_img = [np.reshape(img, (out_vector_shape)) for img in encoded_img] # Flatten the compressed image\n",
    "        density = kde.score_samples(encoded_img)[0] # get a density score for the new image\n",
    "        reconstruction = model.predict([[img]])\n",
    "        reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)[0]\n",
    "        density_list.append(density)\n",
    "        recon_error_list.append(reconstruction_error)\n",
    "        \n",
    "    average_density = np.mean(np.array(density_list))  \n",
    "    stdev_density = np.std(np.array(density_list)) \n",
    "    \n",
    "    average_recon_error = np.mean(np.array(recon_error_list))  \n",
    "    stdev_recon_error = np.std(np.array(recon_error_list)) \n",
    "    \n",
    "    return average_density, stdev_density, average_recon_error, stdev_recon_error\n",
    "\n",
    "#Get average and std dev. of density and recon. error for uninfected and anomaly (parasited) images. \n",
    "#For this let us generate a batch of images for each. \n",
    "train_batch = train_generator.next()[0]\n",
    "anomaly_batch = anomaly_generator.next()[0]\n",
    "\n",
    "uninfected_values = calc_density_and_recon_error(train_batch)\n",
    "anomaly_values = calc_density_and_recon_error(anomaly_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, input unknown images and sort as Good or Anomaly\n",
    "def check_anomaly(img_path):\n",
    "    density_threshold = 2500 #Set this value based on the above exercise\n",
    "    reconstruction_error_threshold = 0.004 # Set this value based on the above exercise\n",
    "    img  = Image.open(img_path)\n",
    "    img = np.array(img.resize((128,128), Image.ANTIALIAS))\n",
    "    plt.imshow(img)\n",
    "    img = img / 255.\n",
    "    img = img[np.newaxis, :,:,:]\n",
    "    encoded_img = encoder_model.predict([[img]]) \n",
    "    encoded_img = [np.reshape(img, (out_vector_shape)) for img in encoded_img] \n",
    "    density = kde.score_samples(encoded_img)[0] \n",
    "\n",
    "    reconstruction = model.predict([[img]])\n",
    "    reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)[0]\n",
    "\n",
    "    if density < density_threshold or reconstruction_error > reconstruction_error_threshold:\n",
    "        print(\"The image is an anomaly\")\n",
    "        \n",
    "    else:\n",
    "        print(\"The image is NOT an anomaly\")\n",
    "        \n",
    "        \n",
    "#Load a couple of test images and verify whether they are reported as anomalies.\n",
    "import glob\n",
    "para_file_paths = glob.glob('cell_images2/parasitized/images/*')\n",
    "uninfected_file_paths = glob.glob('cell_images2/uninfected_train/images/*')\n",
    "\n",
    "#Anomaly image verification\n",
    "num=random.randint(0,len(para_file_paths)-1)\n",
    "check_anomaly(para_file_paths[num])\n",
    "\n",
    "#Good/normal image verification\n",
    "num=random.randint(0,len(para_file_paths)-1)\n",
    "check_anomaly(uninfected_file_paths[num])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
